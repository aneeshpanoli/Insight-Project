{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set - 17226 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup imports and paths\n",
    "import os\n",
    "import sys\n",
    "from os.path import expanduser\n",
    "\n",
    "\n",
    "HOME_DIR = expanduser(\"~\")\n",
    "sys.path.append(HOME_DIR+'/packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load custom Midas tools\n",
    "from Midas import Midas_helper\n",
    "helper = Midas_helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "helper.cd_main_data()\n",
    "#load main Midas labelled data table\n",
    "df = pd.read_csv('midas_labeled_data_Q12018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_note(text):\n",
    "    # Strip HTML tags\n",
    "    text = re.sub('<[^<]+?>', ' ', text)\n",
    " \n",
    "    # Strip escaped quotes\n",
    "    text = text.replace('\\\\\"', '')\n",
    " \n",
    "    # Strip quotes\n",
    "    text = text.replace('\"', '')\n",
    " \n",
    "    return text\n",
    " \n",
    "# df = pd.read_csv('labeledTrainData.tsv', sep='\\t', quoting=3)\n",
    "df.fillna('No Score', inplace=True)\n",
    "df['cleaned_note_unstructured'] = df['cleaned_note_unstructured'].apply(clean_note)\n",
    "df['category_id'] = df['midas_final_unstructured'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map class numerical values\n",
    "midas_final_unstructured_id_df = df[['midas_final_unstructured', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "midas_final_unstructured_id_df.index = midas_final_unstructured_id_df.category_id\n",
    "midas_final_unstructured_id_df.drop('category_id', axis=1, inplace=True)\n",
    "class_dict = midas_final_unstructured_id_df.to_dict()['midas_final_unstructured']\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_note_unstructured'], \n",
    "                                                    df['category_id'], test_size=0.2, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGHT = len(max([i.split() for i in X_train.values], key=len))\n",
    "cv = CountVectorizer(stop_words=stopwords.words('english'), \n",
    "                             lowercase=True, min_df=3, max_df=0.9, max_features=MAX_SEQ_LENGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mult_nb = MultinomialNB()\n",
    "pipe = Pipeline([('cv',cv),\n",
    "                ('model',model_mult_nb)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe,cv=5)\n",
    "print(gs.fit(X_train,y_train))\n",
    "print(gs.best_params_)\n",
    "print(\"Train Score: \", round(gs.best_score_,4))\n",
    "print(\"Train Score: \", round(gs.score(X_test,y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutlinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for alpha in np.linspace(0,2,20)[1:]:\n",
    "X_train_onehot = cv.fit_transform(X_train)\n",
    "X_test_onehot = cv.fit_transform(X_test)\n",
    "\n",
    "model_mult_nb = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "model_mult_nb.fit(X_train_onehot,y_train)\n",
    "print(\"Train score\", model_mult_nb.score(X_train_onehot,y_train))\n",
    "print(\"Test score\", model_mult_nb.score(X_test_onehot,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=2019)\n",
    "rf.fit(X_train_onehot,y_train)\n",
    "print(\"Cross Val Score: \",cross_val_score(rf,X_train_onehot,y_train,cv=5).mean())\n",
    "print(\"Train Score: \", round(rf.score(X_train_onehot,y_train),4))\n",
    "print(\"Test Score: \", round(rf.score(X_test_onehot,y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(random_state=42)\n",
    "et.fit(X_train_onehot,y_train)\n",
    "print(\"Cross Val Score: \",cross_val_score(rf,X_train_onehot,y_train,cv=5).mean())\n",
    "print(\"Train Score: \", round(et.score(X_train_onehot,y_train),4))\n",
    "print(\"Test Score: \", round(et.score(X_test_onehot,y_test),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged = BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=42)\n",
    "                            ,max_samples=0.5, max_features=0.5)\n",
    "bagged.fit(X_train_onehot,y_train)\n",
    "print(\"Cross Val Score: \",cross_val_score(bagged,X_train_onehot,y_train,cv=5).mean())\n",
    "print(\"Train Score: \",bagged.score(X_train_onehot,y_train))\n",
    "print(\"Test Score: \",bagged.score(X_test_onehot,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning random forest with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#saved data is available as a pickle file\n",
    "\n",
    "model__max_features = ['auto',0.75,0.8,0.4]\n",
    "model__max_depth = [65,66,67,68,69,70]#,200]\n",
    "model__criterion = ['gini', 'entropy']\n",
    "sample_leaf_options = [1,5,10,50,100,200,500]\n",
    "results = []\n",
    "for crit in model__criterion:\n",
    "    for feat in model__max_features:\n",
    "        for depth in model__max_depth:\n",
    "#             print (crit, feat,depth) ## min_samples_leaf=model_min_samples_leaf,n_estimators = [20] \n",
    "#             et = ExtraTreesClassifier(random_st ate=42, criterion=crit,max_depth=depth,max_features=feat)\n",
    "            rf = RandomForestClassifier(n_estimators = 10,random_state=42, criterion=crit,max_depth=depth,max_features=feat\n",
    "                                       ,min_samples_leaf = 1)\n",
    "            rf.fit(X_train_onehot,y_train)\n",
    "            cv_score = round(cross_val_score(rf,X_train_onehot,y_train,cv=5).mean(),5)\n",
    "            train_score = round(rf.score(X_train_onehot,y_train),5)\n",
    "            test_score = round(rf.score(X_test_onehot,y_test),5)            \n",
    "            results.append([crit,feat,depth,cv_score,train_score,test_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.cd_main_data()\n",
    "helper.save_as_pickle(results, 'random_forest_gridSearchCv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain random forest with optimum hyperparameters\n",
    "# 'entropy', 'auto', None, 1.0, 0.99856, 0.73593\n",
    "rf = RandomForestClassifier(random_state=2019,criterion='gini',max_features='auto',max_depth=30)\n",
    "rf.fit(X_train_onehot,y_train)\n",
    "print(\"Cross Val Score: \",cross_val_score(rf,X_train_onehot,y_train,cv=5).mean())\n",
    "print(\"Train Score: \", round(rf.score(X_train_onehot,y_train),4))\n",
    "print(\"Test Score: \", round(rf.score(X_test_onehot,y_test),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print random forest top features\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(indices)\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(0,20): # X_train_vec.shape[1]\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]),class_dict[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

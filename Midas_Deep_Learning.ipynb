{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup imports and paths\n",
    "import os\n",
    "import sys\n",
    "from os.path import expanduser\n",
    "\n",
    "\n",
    "HOME_DIR = expanduser(\"~\")\n",
    "sys.path.append(HOME_DIR+'/packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load custom Midas tools\n",
    "from Midas import Midas_helper\n",
    "helper = Midas_helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to class data folder\n",
    "helper.cd_main_data()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#load main Midas labelled data table\n",
    "df = pd.read_csv('midas_labeled_data_Q12018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "def clean_note(text):\n",
    "    # Strip HTML tags\n",
    "    text = re.sub('<[^<]+?>', ' ', text)\n",
    " \n",
    "    # Strip escaped quotes\n",
    "    text = text.replace('\\\\\"', '')\n",
    " \n",
    "    # Strip quotes\n",
    "    text = text.replace('\"', '')\n",
    " \n",
    "    return text\n",
    " \n",
    "# df = pd.read_csv('labeledTrainData.tsv', sep='\\t', quoting=3)\n",
    "df['midas_final_unstructured'].fillna('No Score', inplace=True)\n",
    "# df.dropna(inplace=True)\n",
    "df['cleaned_note_unstructured'] = df['cleaned_note_unstructured'].apply(clean_note)\n",
    "df['category_id'] = df['midas_final_unstructured'].factorize()[0]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_note_unstructured'], \n",
    "                                                    df['category_id'], test_size=0.2, random_state=2019)\n",
    "\n",
    "# important for LIME to work\n",
    "# X_train.reset_index(drop=True, inplace=True)\n",
    "# y_train.reset_index(drop=True, inplace=True)\n",
    "# X_test.reset_index(drop=True, inplace=True)\n",
    "# y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midas_final_unstructured_id_df = df[['midas_final_unstructured', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "\n",
    "midas_final_unstructured_id_df.index = midas_final_unstructured_id_df.category_id\n",
    "midas_final_unstructured_id_df.drop('category_id', axis=1, inplace=True)\n",
    "class_dict = midas_final_unstructured_id_df.to_dict()['midas_final_unstructured']\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "MAX_SEQ_LENGTH = len(max([i.split() for i in X_train.values], key=len))\n",
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), \n",
    "                             lowercase=True, min_df=3, max_df=0.9, max_features=MAX_SEQ_LENGTH)\n",
    "X_train_onehot = vectorizer.fit_transform(X_train)\n",
    "X_test_onehot = vectorizer.fit_transform(X_test)\n",
    "MAX_SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN -model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "model = Sequential()\n",
    " \n",
    "model.add(Dense(units=MAX_SEQ_LENGTH, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    " #sparse is important\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_onehot[:-100], y_train[:-100], \n",
    "          epochs=2, batch_size=128, verbose=1, \n",
    "          validation_data=(X_train_onehot[-100:], y_train[-100:]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(vectorizer.transform(X_test), y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN - model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Dense(units=MAX_SEQ_LENGTH, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n",
    "model.add(Dense(units=int(2048), activation='relu'))\n",
    "model.add(Dense(units=int(1024), activation='relu'))\n",
    "model.add(Dense(units=int(512), activation='relu'))\n",
    "model.add(Dense(units=int(256), activation='relu'))\n",
    "model.add(Dense(units=int(128), activation='relu'))\n",
    "model.add(Dense(units=int(64), activation='relu'))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    " #sparse is important\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dnn_train(model, epoch):\n",
    "    history = model.fit(X_train_onehot[:-100], y_train[:-100], \n",
    "              epochs=epoch, batch_size=128, verbose=1, \n",
    "              validation_data=(X_train_onehot[-100:], y_train[-100:]))\n",
    "    scores = model.evaluate(vectorizer.transform(X_test), y_test, verbose=1)\n",
    "    print(\"Accuracy:\", scores[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN - model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Dense(units=MAX_SEQ_LENGTH, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n",
    "model.add(Dense(units=int(2048), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=int(1024), activation='relu'))\n",
    "model.add(Dense(units=int(512), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=int(256), activation='relu'))\n",
    "model.add(Dense(units=int(128), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=int(64), activation='relu'))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    " #sparse is important\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_train(model, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Dense(units=MAX_SEQ_LENGTH, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n",
    "model.add(Dense(units=int(2048), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=int(1024), activation='relu'))\n",
    "model.add(Dense(units=int(512), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=int(256), activation='relu'))\n",
    "model.add(Dense(units=int(128), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=int(64), activation='relu'))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    " #sparse is important\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_train(model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "# plot loss during training\n",
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
    "def get_metrics(model, testX, testy):\n",
    "    yhat_probs = model.predict(testX, verbose=0)\n",
    "    # predict crisp classes for test set\n",
    "    yhat_classes = model.predict_classes(testX, verbose=0)\n",
    "    print(yhat_classes)\n",
    "    # reduce to 1d array\n",
    "    yhat_probs = yhat_probs[:, 0]\n",
    "#     yhat_classes = yhat_classes[:, 0]\n",
    "    \n",
    "\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(testy, yhat_classes)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(testy, yhat_classes, average='micro')\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(testy, yhat_classes, average='micro')\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(testy, yhat_classes, average='micro')\n",
    "    print('F1 score: %f' % f1)\n",
    "\n",
    "    # kappa\n",
    "    kappa = cohen_kappa_score(testy, yhat_classes)\n",
    "    print('Cohens kappa: %f' % kappa)\n",
    "    # ROC AUC\n",
    "#     auc = roc_auc_score(testy, yhat_probs)\n",
    "#     print('ROC AUC: %f' % auc)\n",
    "    # confusion matrix\n",
    "    matrix = confusion_matrix(testy, yhat_classes)\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Text for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd class_tables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process for prediction\n",
    "pred_df = pd.read_csv('midas_labeled_data_Q12018_NaN_only.csv', nrows=1000)\n",
    "pred_df['cleaned_note_unstructured'].dropna(inplace=True)\n",
    "pred_df = pd.DataFrame(pred_df['cleaned_note_unstructured'], columns=['cleaned_note_unstructured'])\n",
    "type(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results(scores, df, class_dict):\n",
    "    arg_max = []\n",
    "    for i in scores:\n",
    "        arg_max.append(i.argmax())\n",
    "\n",
    "    df_prediction = df.copy(deep=True)\n",
    "    df_prediction['midas_score'] = [class_dict[i] for i in arg_max]\n",
    "    pd.options.display.max_colwidth = 2000\n",
    "    return df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(vectorizer.transform(pred_df.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_resutls = prediction_results(prediction, pred_df, class_dict)\n",
    "pred_resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "c = make_pipeline(vectorizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = class_dict.values\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_onehot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "exp = explainer.explain_instance(X_test[idx], c.predict_proba, num_features=6, labels=[0, 1])\n",
    "print('Document id: %d' % idx)\n",
    "print('Predicted class =', class_names[int(model.predict(X_test_onehot[idx]).reshape(1,-1)[0,0])])\n",
    "print('True class: %s' % class_names[y_test[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Explanation for class %s' % class_names[0])\n",
    "print ('\\n'.join(map(str, exp.as_list(label=0))))\n",
    "print ()\n",
    "print ('Explanation for class %s' % class_names[1])\n",
    "print ('\\n'.join(map(str, exp.as_list(label=17))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(model, vectorizer.transform(pred_df.squeeze()), y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def explain_the_model(idx, label=[0]):\n",
    "    ''' idx: index of the row in pred_df\n",
    "    pred_df - data on which the predictions to be made\n",
    "    '''\n",
    "    class_names = midas_final_unstructured_id_df['midas_final_unstructured'].values.tolist()\n",
    "    print('Class names: {}'.format(class_names))\n",
    "    explainer = LimeTextExplainer(class_names=class_names)\n",
    "    c = make_pipeline(vectorizer, model)\n",
    "    print(X_test[idx])\n",
    "    exp = explainer.explain_instance(X_test[idx], c.predict_proba, num_features=6, labels=label)\n",
    "    print('Document id: %d' % idx)\n",
    "    print('Predicted class =', class_names[int(model.predict(\n",
    "        vectorizer.transform(pred_df.squeeze())[idx]).reshape(1,-1)[0,0])])\n",
    "    print('True class: %s' % class_names[y_test[idx]])\n",
    "    print ('Explanation for class %s' % class_names[0])\n",
    "    print ('\\n'.join(map(str, exp.as_list(label=0))))\n",
    "    print ()\n",
    "    print ('Explanation for class %s' % class_names[1])\n",
    "    print ('\\n'.join(map(str, exp.as_list(label=1))))\n",
    "    exp.show_in_notebook(text=False)\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "class_names = midas_final_unstructured_id_df['midas_final_unstructured'].values.tolist()\n",
    "c = make_pipeline(vectorizer, model)\n",
    "print('Class names: {}'.format(class_names))\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "exp = explainer.explain_instance(X_test[idx], c.predict_proba, num_features=6, labels=label)\n",
    "print('Document id: %d' % idx)\n",
    "print('Predicted class =', class_names[int(model.predict(\n",
    "    vectorizer.transform(pred_df.squeeze())[idx]).reshape(1,-1)[0,0])])\n",
    "print('True class: %s' % class_names[y_test[idx]])\n",
    "print ('Explanation for class %s' % class_names[0])\n",
    "print ('\\n'.join(map(str, exp.as_list(label=0))))\n",
    "print ()\n",
    "print ('Explanation for class %s' % class_names[1])\n",
    "print ('\\n'.join(map(str, exp.as_list(label=1))))\n",
    "exp.show_in_notebook(text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['cleaned_note_unstructured'][40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 40#row number of unlabelled data\n",
    "# exp = explain_the_model(idx, [0, 1])\n",
    "exp.show_in_notebook(text=X_test[idx], labels=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save('DNN_0.853.h5') # 250 gigs\n",
    "\n",
    "# Deletes the existing model\n",
    "# del model  \n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word2idx = {word: idx for idx, word in enumerate(vectorizer.get_feature_names())}\n",
    "tokenize = vectorizer.build_tokenizer()\n",
    "preprocess = vectorizer.build_preprocessor()\n",
    " \n",
    "def to_sequence(tokenizer, preprocessor, index, text):\n",
    "    words = tokenizer(preprocessor(text))\n",
    "    indexes = [index[word] for word in words if word in index]\n",
    "    return indexes\n",
    " \n",
    "print(to_sequence(tokenize, preprocess, word2idx, \"This is an important test!\"))  # [2269, 4453]\n",
    "X_train_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in X_train]\n",
    "print(X_train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the max length of a text\n",
    "MAX_SEQ_LENGTH = len(max(X_train_sequences, key=len))\n",
    "print(\"MAX_SEQ_LENGTH=\", MAX_SEQ_LENGTH)\n",
    " \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "N_FEATURES = len(vectorizer.get_feature_names())\n",
    "X_train_sequences = pad_sequences(X_train_sequences, maxlen=MAX_SEQ_LENGTH, value=N_FEATURES)\n",
    "print(X_train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vectorizer.get_feature_names()) + 1,\n",
    "                    64,  # Embedding size\n",
    "                    input_length=MAX_SEQ_LENGTH))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    " \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(X_train_sequences[:-100], y_train[:-100], \n",
    "          epochs=3, batch_size=512, verbose=1,\n",
    "          validation_data=(X_train_sequences[-100:], y_train[-100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in X_test]\n",
    "X_test_sequences = pad_sequences(X_test_sequences, maxlen=MAX_SEQ_LENGTH, value=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test_sequences, y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('CNN_0.664.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Embedding\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vectorizer.get_feature_names()) + 1,\n",
    "                    64,  # Embedding size\n",
    "                    input_length=MAX_SEQ_LENGTH))\n",
    "model.add(Conv1D(256, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    " \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(X_train_sequences[:-100], y_train[:-100], \n",
    "          epochs=3, batch_size=512, verbose=1,\n",
    "          validation_data=(X_train_sequences[-100:], y_train[-100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in X_test]\n",
    "X_test_sequences = pad_sequences(X_test_sequences, maxlen=MAX_SEQ_LENGTH, value=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test_sequences, y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vectorizer.get_feature_names()) + 1,\n",
    "                    64,  # Embedding size\n",
    "                    input_length=MAX_SEQ_LENGTH))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    " \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_sequences[:-100], y_train[:-100], \n",
    "          epochs=2, batch_size=128, verbose=1, \n",
    "          validation_data=(X_train_sequences[-100:], y_train[-100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test_sequences, y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1]) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('LSTM_0.723.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en') #python -m spacy download en\n",
    " \n",
    "EMBEDDINGS_LEN = len(nlp.vocab['apple'].vector)\n",
    "print(\"EMBEDDINGS_LEN=\", EMBEDDINGS_LEN)  # 300\n",
    " \n",
    "embeddings_index = np.zeros((len(vectorizer.get_feature_names()) + 1, EMBEDDINGS_LEN))\n",
    "for word, idx in word2idx.items():\n",
    "    try:\n",
    "        embedding = nlp.vocab[word].vector\n",
    "        embeddings_index[idx] = embedding\n",
    "    except:\n",
    "        pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vectorizer.get_feature_names()) + 1,\n",
    "                    EMBEDDINGS_LEN,  # Embedding size\n",
    "                    weights=[embeddings_index],\n",
    "                    input_length=MAX_SEQ_LENGTH,\n",
    "                    trainable=False))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    " \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_sequences[:-100], y_train[:-100], \n",
    "          epochs=1, batch_size=128, verbose=1, \n",
    "          validation_data=(X_train_sequences[-100:], y_train[-100:]))\n",
    " \n",
    "scores = model.evaluate(X_test_sequences, y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1])  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.cd_main_data()\n",
    "!wget -O glove.6B.zip http://nlp.stanford.edu/data/glove.6B.zip\n",
    "helper.unzip('glove.6B.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "GLOVE_PATH = HOME_DIR+'/main_data/glove.6B/glove.6B.50d.txt'\n",
    "GLOVE_VECTOR_LENGTH = 50\n",
    " \n",
    "def read_glove_vectors(path, length):\n",
    "    embeddings = {}\n",
    "    with open(path) as glove_f:\n",
    "        for line in glove_f:\n",
    "            chunks = line.split()\n",
    "            assert len(chunks) == length + 1\n",
    "            embeddings[chunks[0]] = np.array(chunks[1:], dtype='float32')\n",
    " \n",
    "    return embeddings\n",
    " \n",
    "GLOVE_INDEX = read_glove_vectors(GLOVE_PATH, GLOVE_VECTOR_LENGTH)\n",
    " \n",
    "# Init the embeddings layer with GloVe embeddings\n",
    "embeddings_index = np.zeros((len(vectorizer.get_feature_names()) + 1, GLOVE_VECTOR_LENGTH))\n",
    "for word, idx in word2idx.items():\n",
    "    try:\n",
    "        embedding = GLOVE_INDEX[word]\n",
    "        embeddings_index[idx] = embedding\n",
    "    except:\n",
    "        pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vectorizer.get_feature_names()) + 1,\n",
    "                    GLOVE_VECTOR_LENGTH,  # Embedding size\n",
    "                    weights=[embeddings_index],\n",
    "                    input_length=MAX_SEQ_LENGTH,\n",
    "                    trainable=False))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    " \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    " \n",
    "model.fit(X_train_sequences[:-100], y_train[:-100], \n",
    "          epochs=3, batch_size=128, verbose=1, \n",
    "          validation_data=(X_train_sequences[-100:], y_train[-100:]))\n",
    " \n",
    "scores = model.evaluate(X_test_sequences, y_test, verbose=1)\n",
    "print(\"Test Accuracy:\", scores[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('GloVe_0.671.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model input shape should be the length of the longest text in the data\n",
    "def prepare_text_for_pred(df):\n",
    "    X_pred_sequences = [to_sequence(tokenize, preprocess, word2idx, x) for x in df.squeeze()]\n",
    "    MAX_SEQ_LENGTH = len(max(X_train_sequences, key=len))\n",
    "    return pad_sequences(X_pred_sequences, maxlen=MAX_SEQ_LENGTH, value=N_FEATURES)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv('midas_labeled_data_Q12018_grade1_only.csv', nrows=10)\n",
    "pred_df.dropna(inplace=True)\n",
    "pred_df = pd.DataFrame(pred_df['cleaned_note_unstructured'], columns=['cleaned_note_unstructured'])\n",
    "type(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_sequences = prepare_text_for_pred(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(X_pred_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_results(scores, df, class_dict):\n",
    "    arg_max = []\n",
    "    for i in scores:\n",
    "        arg_max.append(i.argmax())\n",
    "\n",
    "    df_prediction = df.copy(deep=True)\n",
    "    df_prediction['midas_score'] = [class_dict[i] for i in arg_max]\n",
    "    pd.options.display.max_colwidth = 2000\n",
    "    return df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arg_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

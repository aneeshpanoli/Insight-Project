{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup imports and paths\n",
    "import os\n",
    "import sys\n",
    "from os.path import expanduser\n",
    "\n",
    "\n",
    "HOME_DIR = expanduser(\"~\")\n",
    "sys.path.append(HOME_DIR+'/packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load custom Midas tools\n",
    "from Midas import Midas_helper\n",
    "helper = Midas_helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.cd_main_data()\n",
    "import pandas as pd\n",
    "#load main Midas labelled data table\n",
    "df = pd.read_csv('midas_labeled_data_Q12018.csv')\n",
    "df['midas_final_unstructured'].fillna('No Score', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insight = df[['cleaned_note_unstructured', 'snippet_unstructured', 'midas_final_unstructured']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(df['midas_final_unstructured'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insight.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map labels to numerical value\n",
    "labels = list(lbl_enc.inverse_transform(y))\n",
    "class_dict = dict(zip(labels, y))\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpred = df['snippet_unstructured'].values\n",
    "ypred = df['midas_final_unstructured'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer \n",
    "ctv.fit(list(xpred))\n",
    "xpred_ctv =  ctv.transform(xpred) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(HOME_DIR+'/main_data/models')\n",
    "# load the model from disk\n",
    "from sklearn.externals import joblib\n",
    "filename = 'XGB_ctv_snippet_0.071.sav'\n",
    "clf = joblib.load(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(class_dict.values())\n",
    "predictions = clf.predict_proba(xpred_ctv.tocsc())\n",
    "for i, j in enumerate(predictions):\n",
    "     print(('IDX:{} | Class: {} - {} | Proba: {}').format(i, j.argmax(), class_names[j.argmax()], max(j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#classes\n",
    "class_names = list(class_dict.keys())\n",
    "\n",
    "#make pipeline\n",
    "pipe = make_pipeline(ctv, clf)\n",
    "\n",
    "#instantiate explainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict and analyze labelled data\n",
    "def predict_analyze_labelled(idx, highlight=False):\n",
    "    print('Row ID: {}| Text : {}'.format(idx, xpred[idx]))\n",
    "    exp = explainer.explain_instance(xpred[idx], pipe.predict_proba, num_features=6, labels=[0, 1, 2, 3, 4, 5])\n",
    "    pred_class = clf.predict(xpred_ctv.tocsc()[idx]).reshape(1,-1)[0,0]\n",
    "    print('Predicted class =', class_names[pred_class])\n",
    "    print('True class: %s' % class_names[y[idx]])\n",
    "    print ('Explanation for class %s' % class_names[pred_class])\n",
    "    print ('\\n'.join(map(str, exp.as_list(label=pred_class))))\n",
    "    \n",
    "    if highlight:\n",
    "        exp.show_in_notebook(text=xpred[idx], labels=(pred_class,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    predict_analyze_labelled(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file\n",
    "helper.cd_main_data()\n",
    "csv_name = 'midas_unlabelled_patient_note_aggregate_Jan18.csv'\n",
    "df_unlabelled = pd.read_csv(csv_name, nrows=100000)\n",
    "df_unlabelled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabelled['cleaned_notes'].dropna(inplace=True)\n",
    "unlabelled_pred = df_unlabelled['cleaned_notes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer \n",
    "ctv.fit(list(xpred))\n",
    "unlabelled_pred_ctv =  ctv.transform(unlabelled_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_unl = clf.predict_proba(unlabelled_pred_ctv.tocsc())\n",
    "for i, j in enumerate(predictions_unl):\n",
    "    if max(j) > 0.8:\n",
    "        print(('IDX:{} | Class: {} - {} | Proba: {}').format(i, j.argmax(), class_names[j.argmax()], max(j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make pipeline\n",
    "pipe = make_pipeline(ctv, clf)\n",
    "\n",
    "#instantiate explainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict and analyze labelled data\n",
    "def predict_analyze_labelled(idx, highlight=False):\n",
    "    print('Row ID: {}| Text : {}'.format(idx, unlabelled_pred[idx]))\n",
    "    exp = explainer.explain_instance(unlabelled_pred[idx], pipe.predict_proba, num_features=6, labels=[0, 1, 2, 3, 4, 5])\n",
    "    pred_class = clf.predict(unlabelled_pred_ctv.tocsc()[idx]).reshape(1,-1)[0,0]\n",
    "    print('Predicted class =', class_names[pred_class])\n",
    "    print ('Explanation for class %s' % class_names[pred_class])\n",
    "    print ('\\n'.join(map(str, exp.as_list(label=pred_class))))\n",
    "    \n",
    "    if highlight:\n",
    "        exp.show_in_notebook(text=xpred[idx], labels=(pred_class,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe.predict_proba([unlabelled_pred[0]]).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_analyze_labelled(883, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
